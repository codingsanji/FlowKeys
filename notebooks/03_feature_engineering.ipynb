{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f36a9fdf",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "import matplotlib.pyplot as plt\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3568e510",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"../data/keystrokes/raw/fixed-text.csv\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c10e64d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw = df.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0fc194e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "timing_cols = df.columns[3:-1] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c874fac7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean = df.copy()\n",
                "df_clean[timing_cols] = df_clean[timing_cols].apply(pd.to_numeric, errors='coerce')\n",
                "df_clean[timing_cols] = df_clean[timing_cols].clip(lower=0)\n",
                "df_clean[timing_cols] = df_clean[timing_cols].fillna(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a8f6ab31",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_features(df):\n",
                "    timing_cols = df.columns[3:-1]\n",
                "\n",
                "    df['mean_timing'] = df[timing_cols].mean(axis=1)\n",
                "    df['std_timing'] = df[timing_cols].std(axis=1)\n",
                "    df['min_timing'] = df[timing_cols].min(axis=1)\n",
                "    df['max_timing'] = df[timing_cols].max(axis=1)\n",
                "    df['median_timing'] = df[timing_cols].median(axis=1)\n",
                "\n",
                "    df['WPM'] = 120 / df['total time']\n",
                "\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83719d84",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw = create_features(df_raw)\n",
                "df_clean = create_features(df_clean)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b53ae287",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f3df7fba",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "30ecfa07",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean[[\"mean_timing\", \"std_timing\", \"min_timing\", \"max_timing\", \n",
                "          \"median_timing\", \"total time\"]].hist(bins=30, figsize=(12,8))\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "642d6829",
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_cols = ['mean_timing','std_timing','min_timing','max_timing','median_timing','total time']\n",
                "target_col = 'WPM'\n",
                "\n",
                "# RAW\n",
                "X_raw = df_raw[feature_cols]\n",
                "y_raw = df_raw[target_col]\n",
                "\n",
                "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
                "    X_raw, y_raw, test_size=0.3, random_state=42\n",
                ")\n",
                "\n",
                "# CLEANED\n",
                "X_clean = df_clean[feature_cols]\n",
                "y_clean = df_clean[target_col]\n",
                "\n",
                "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
                "    X_clean, y_clean, test_size=0.3, random_state=42\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4be367d6",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6beb44e",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preprocessing for Fixed Text Keystroke Dynamics\n",
                "### Cleaning Data, Handling Negative Values (Overlap), and Calculating Target Variable (WPM)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Data Preprocessing for Fixed Text Keystroke Dynamics ---\n",
                "\n",
                "# NOTE: If you previously loaded the data into a DataFrame named 'df' or 'df_raw',\n",
                "# ensure you use the correct variable here. We assume 'df' is loaded or is loaded here.\n",
                "try:\n",
                "    # Attempt to read the file in the current working directory\n",
                "    df = pd.read_csv(\"fixed-text.csv\")\n",
                "except FileNotFoundError:\n",
                "    # Fallback/Suggestion: Use the relative path often seen in your notebook structure\n",
                "    # df = pd.read_csv(\"../data/keystrokes/raw/fixed-text.csv\")\n",
                "    print(\"Error: 'fixed-text.csv' not found. Please adjust the file path.\")\n",
                "    # Stop execution if data cannot be loaded\n",
                "    # exit()\n",
                "\n",
                "# Identify all float columns for outlier checking and feature usage\n",
                "float_cols = df.select_dtypes(include=['float64']).columns\n",
                "\n",
                "# --- 2. Handle Corrupted Negative Outliers ---\n",
                "# Small negative values (representing key overlap) are kept AS-IS, as they are meaningful features.\n",
                "# Only the massive negative values (sentinel codes for corrupted data) are removed.\n",
                "\n",
                "OUTLIER_THRESHOLD = -1000000\n",
                "\n",
                "# Create a mask to identify rows where ANY float column is below the outlier threshold\n",
                "outlier_rows_mask = (df[float_cols] < OUTLIER_THRESHOLD).any(axis=1)\n",
                "\n",
                "# Remove the identified outlier rows\n",
                "df_cleaned = df[~outlier_rows_mask].copy()\n",
                "\n",
                "# Report on the cleaning step\n",
                "removed_rows_count = outlier_rows_mask.sum()\n",
                "print(f\"Removed {removed_rows_count} row(s) containing corrupted sentinel negative values.\")\n",
                "print(f\"Remaining rows in dataset: {len(df_cleaned)}\")\n",
                "\n",
                "\n",
                "# --- 3. Calculate Target Variable: Word Per Minute (WPM) ---\n",
                "# The fixed text is \"vp wjkeurkb\", which has 10 characters (keys).\n",
                "NUM_CHARS = 10 \n",
                "\n",
                "# WPM calculation: (Characters / 5) / (Total Time in minutes)\n",
                "df_cleaned['WPM'] = (NUM_CHARS / 5) / (df_cleaned['total time'] / 60)\n",
                "\n",
                "\n",
                "# --- 4. Prepare Final Feature Set and Save ---\n",
                "# Exclude 'total time' from features as WPM is directly derived from it.\n",
                "feature_cols = [col for col in float_cols if col not in ['total time']]\n",
                "\n",
                "# Final DataFrame structure for ML\n",
                "df_ml = df_cleaned[['participant', 'session', 'repetition', 'WPM'] + feature_cols].copy()\n",
                "\n",
                "# Save the Cleaned Data \n",
                "output_filename = \"fixed_text_cleaned_for_ml.csv\"\n",
                "df_ml.to_csv(output_filename, index=False)\n",
                "\n",
                "print(f\"\\nCleaned and preprocessed data saved to '{output_filename}'.\")\n",
                "print(\"\\nFirst 5 rows of the final ML-ready DataFrame with WPM:\")\n",
                "print(df_ml.head())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
